training:
  num_workers: 10
  batch_size: 10
  exp_name: ''
  epochs: 20
  lr: 0.001
  weight_decay: 0.001 # 0.01 for training from scratch best result
  momentum: 0.9
  lr_scheduler: cosine
  opt: ADAM
  lr_peak_epoch: 10
  label_smoothing: 0.0
  disable_logging: False
  data_root: "/mnt/xfs/projects/proteins/datasets/multichain/multichain_wds_zip"
  only_non_bn_weight_decay: False
  mixed_precision: 1
  self_supervised: 0
  max_seq_len: 1024
  burn_in: 0
  freeze_llm: 0
logging:
  do_if_complete: False
  mmap_logdir: ""
model:
  arch: "facebook/esm2_t30_150M_UR50D"
  coordinator_hparams: "terminator_configs/coordinator.json"
  gnn_checkpoint: ''
data:
    train_wds_path: multichain_train.zip
    val_wds_path: multichain_clip_val.wds #multichain_val.zip
distributed:
  distributed: 0
  world_size: 1
  address: localhost
  dist_train_len: 170000
  dist_val_len: 4200
clip_batching:
  zip_enabled: 1
  zip_train_format_string: train/sample{:06d}.inp.pyd
  cath_info_dict: /mnt/xfs/projects/proteins/cath_families/multichain/augmented_cath_balanced_split_mc_V2.pt
  zip_num_steps_per_epoch: 1300